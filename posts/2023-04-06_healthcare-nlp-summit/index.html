<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Healthcare NLP Summit write-up | Markus Bockhacker</title>
<meta name=keywords content="NLP,healthcare,conference,notes"><meta name=description content="I spent the last two evenings attending John Snow Labs&rsquo; virtual &ldquo;Healthcare NLP Summit,&rdquo; and I found it to be a stimulating event. If you couldn&rsquo;t attend, here are my notes:
LLMs are all the hype Large-language-models (LLMs) were the overarching topic of the conference, and some speakers (particularly from marketing and sales) were excited about the possibilities. However, there wasn&rsquo;t a clear vision of what these possibilities entailed. Senior researchers and executives had a different sentiment."><meta name=author content="Markus Bockhacker"><link rel=canonical href=https://markus.bockhacker.com/posts/2023-04-06_healthcare-nlp-summit/><link crossorigin=anonymous href=/assets/css/stylesheet.b609c58d5c11bb90b1a54e04005d74ad1ddf22165eb79f5533967e57df9c3b50.css integrity="sha256-tgnFjVwRu5CxpU4EAF10rR3fIhZet59VM5Z+V9+cO1A=" rel="preload stylesheet" as=style><link rel=icon href=https://markus.bockhacker.com/img/apple-touch-icon.png><link rel=icon type=image/png sizes=16x16 href=https://markus.bockhacker.com/img/16x16.png><link rel=icon type=image/png sizes=32x32 href=https://markus.bockhacker.com/img/32x32.png><link rel=apple-touch-icon href=https://markus.bockhacker.com/img/apple-touch-icon.png><link rel=mask-icon href=https://markus.bockhacker.com/img/apple-touch-icon.png><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=en href=https://markus.bockhacker.com/posts/2023-04-06_healthcare-nlp-summit/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><meta property="og:title" content="Healthcare NLP Summit write-up"><meta property="og:description" content="I spent the last two evenings attending John Snow Labs&rsquo; virtual &ldquo;Healthcare NLP Summit,&rdquo; and I found it to be a stimulating event. If you couldn&rsquo;t attend, here are my notes:
LLMs are all the hype Large-language-models (LLMs) were the overarching topic of the conference, and some speakers (particularly from marketing and sales) were excited about the possibilities. However, there wasn&rsquo;t a clear vision of what these possibilities entailed. Senior researchers and executives had a different sentiment."><meta property="og:type" content="article"><meta property="og:url" content="https://markus.bockhacker.com/posts/2023-04-06_healthcare-nlp-summit/"><meta property="article:section" content="posts"><meta property="article:published_time" content="2023-04-06T00:00:00+00:00"><meta property="article:modified_time" content="2023-04-06T00:00:00+00:00"><meta property="og:site_name" content="MB"><meta name=twitter:card content="summary"><meta name=twitter:title content="Healthcare NLP Summit write-up"><meta name=twitter:description content="I spent the last two evenings attending John Snow Labs&rsquo; virtual &ldquo;Healthcare NLP Summit,&rdquo; and I found it to be a stimulating event. If you couldn&rsquo;t attend, here are my notes:
LLMs are all the hype Large-language-models (LLMs) were the overarching topic of the conference, and some speakers (particularly from marketing and sales) were excited about the possibilities. However, there wasn&rsquo;t a clear vision of what these possibilities entailed. Senior researchers and executives had a different sentiment."><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"https://markus.bockhacker.com/posts/"},{"@type":"ListItem","position":2,"name":"Healthcare NLP Summit write-up","item":"https://markus.bockhacker.com/posts/2023-04-06_healthcare-nlp-summit/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"Healthcare NLP Summit write-up","name":"Healthcare NLP Summit write-up","description":"I spent the last two evenings attending John Snow Labs\u0026rsquo; virtual \u0026ldquo;Healthcare NLP Summit,\u0026rdquo; and I found it to be a stimulating event. If you couldn\u0026rsquo;t attend, here are my notes:\nLLMs are all the hype Large-language-models (LLMs) were the overarching topic of the conference, and some speakers (particularly from marketing and sales) were excited about the possibilities. However, there wasn\u0026rsquo;t a clear vision of what these possibilities entailed. Senior researchers and executives had a different sentiment.","keywords":["NLP","healthcare","conference","notes"],"articleBody":"I spent the last two evenings attending John Snow Labs’ virtual “Healthcare NLP Summit,” and I found it to be a stimulating event. If you couldn’t attend, here are my notes:\nLLMs are all the hype Large-language-models (LLMs) were the overarching topic of the conference, and some speakers (particularly from marketing and sales) were excited about the possibilities. However, there wasn’t a clear vision of what these possibilities entailed. Senior researchers and executives had a different sentiment. Elliot Bolton from Stanford CRFM discussed his experiences benchmarking BioMedLM against Med-PaLM and GPT-4. He noted that it is almost impossible for smaller research labs and startups to compete with larger players in the space of LLMs because of the resources required for training LLMs at the scale of GPT-3 / 4.\nMy Opinion: Healthcare professionals should avoid using hosted LLM APIs, even for research projects. Veysel Kocaman from John Snow Labs emphasized the importance of hosting models on-premise for training, specialization, and inference. This is especially true when working with patient data. In Germany, for instance, physicians are strictly prohibited from sharing even pseudonymized data with third parties without patients’ consent. Even with consent, physicians could be criminally liable if unwanted re-identification occurs.\nMeaningless accuracy scores Measuring accuracy has become ridiculous in some cases. Presenters often showcased accuracy scores for clinically meaningless tests, such as “their LLM passing the USMLE practice exam,” PubMedQA, and MedQA. Some implied that these models would generalize to real-world data from electronic health records (EHRs) without requiring much specialization. This is like thinking a first-year resident in internal medicine is capable of diagnosing and treating Ewing-Sarkomas because they passed the USMLE and read the relevant literature.\nAn incomplete list of notable exceptions contains Paulo Pinho, Sudhakar Velamoor, Brooke Gruman, Natalia Vassilieva and Nasser Ghadiri who presented real-world use cases for NLP and accuracies within their development process or different evolutions of their models/ensembles. These were the insights I was looking for.\nInference needs quality control Several presenters invested substantial efforts into autonomous (rules-based) quality-control frameworks, which verify inference results before inclusion in their products. Saira Kazmi Ph. D. gave an excellent presentation on the importance of wrapping an NLP model into an API and creating processes and monitoring to capture the entire life cycle of the product.\nJohn Snow Labs released an early-stage library to automate testing of NER and text-classification models called “nlptest” (https://nlptest.org), which looks promising. I’m definitely going to try it, especially since it’s api-compatible with Hugging Face and spaCy. Their proposed development cycle, which first augments the training data, and then tests for bias, robustness, accuracy and fairness seems pretty slick.\nFew-Shot Learning is definitely worth a try Moshe Wasserblat from Intel presented their paper on “Efficient Few-Shot Learning Without Prompts,” which introduced SetFit. This looks really interesting and I plan to try SetFit on one of my problems where annotated data is difficult to obtain. Especially since one of the authors (Luke Bates) currently resides in Darmstadt. ;-) Link to the Paper: https://arxiv.org/abs/2209.11055\nSummary Overall, the conference lacked substance in some presentations, but it provided great insights into the development of real-world products. I would recommend attending next time.\n","wordCount":"527","inLanguage":"en","datePublished":"2023-04-06T00:00:00Z","dateModified":"2023-04-06T00:00:00Z","author":{"@type":"Person","name":"Markus Bockhacker"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://markus.bockhacker.com/posts/2023-04-06_healthcare-nlp-summit/"},"publisher":{"@type":"Organization","name":"Markus Bockhacker","logo":{"@type":"ImageObject","url":"https://markus.bockhacker.com/img/apple-touch-icon.png"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://markus.bockhacker.com/ accesskey=h title="  (Alt + H)"><img src=https://markus.bockhacker.com/img/apple-touch-icon.png alt aria-label=logo height=35></a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://markus.bockhacker.com/tags/ title=tags><span>tags</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href=https://markus.bockhacker.com/>Home</a>&nbsp;»&nbsp;<a href=https://markus.bockhacker.com/posts/>Posts</a></div><h1 class="post-title entry-hint-parent">Healthcare NLP Summit write-up</h1><div class=post-meta><span title='2023-04-06 00:00:00 +0000 UTC'>April 6, 2023</span>&nbsp;·&nbsp;3 min&nbsp;·&nbsp;527 words&nbsp;·&nbsp;Markus Bockhacker</div></header><div class=post-content><p>I spent the last two evenings attending John Snow Labs&rsquo; virtual &ldquo;Healthcare NLP Summit,&rdquo; and I found it to be a stimulating event. If you couldn&rsquo;t attend, here are my notes:</p><h2 id=llms-are-all-the-hype>LLMs are all the hype<a hidden class=anchor aria-hidden=true href=#llms-are-all-the-hype>#</a></h2><p>Large-language-models (LLMs) were the overarching topic of the conference, and some speakers (particularly from marketing and sales) were excited about the possibilities. However, there wasn&rsquo;t a clear vision of what these possibilities entailed.
Senior researchers and executives had a different sentiment. Elliot Bolton from Stanford CRFM discussed his experiences benchmarking BioMedLM against Med-PaLM and GPT-4. He noted that it is almost impossible for smaller research labs and startups to compete with larger players in the space of LLMs because of the resources required for training LLMs at the scale of GPT-3 / 4.</p><p>My Opinion: Healthcare professionals should avoid using hosted LLM APIs, even for research projects. Veysel Kocaman from John Snow Labs emphasized the importance of hosting models on-premise for training, specialization, and inference. This is especially true when working with patient data. In Germany, for instance, physicians are strictly prohibited from sharing even pseudonymized data with third parties without patients&rsquo; consent. Even with consent, physicians could be criminally liable if unwanted re-identification occurs.</p><p><img loading=lazy src=./line-go-up.png alt="line go up" title="Line go up"></p><h2 id=meaningless-accuracy-scores>Meaningless accuracy scores<a hidden class=anchor aria-hidden=true href=#meaningless-accuracy-scores>#</a></h2><p>Measuring accuracy has become ridiculous in some cases. Presenters often showcased accuracy scores for clinically meaningless tests, such as &ldquo;their LLM passing the USMLE practice exam,&rdquo; PubMedQA, and MedQA. Some implied that these models would generalize to real-world data from electronic health records (EHRs) without requiring much specialization. This is like thinking a first-year resident in internal medicine is capable of diagnosing and treating Ewing-Sarkomas because they passed the USMLE and read the relevant literature.</p><p>An incomplete list of notable exceptions contains Paulo Pinho, Sudhakar Velamoor, Brooke Gruman, Natalia Vassilieva and Nasser Ghadiri who presented real-world use cases for NLP and accuracies within their development process or different evolutions of their models/ensembles. These were the insights I was looking for.</p><h2 id=inference-needs-quality-control>Inference needs quality control<a hidden class=anchor aria-hidden=true href=#inference-needs-quality-control>#</a></h2><p>Several presenters invested substantial efforts into autonomous (rules-based) quality-control frameworks, which verify inference results before inclusion in their products. Saira Kazmi Ph. D. gave an excellent presentation on the importance of wrapping an NLP model into an API and creating processes and monitoring to capture the entire life cycle of the product.</p><p>John Snow Labs released an early-stage library to automate testing of NER and text-classification models called &ldquo;nlptest&rdquo; (<a href=https://nlptest.org>https://nlptest.org</a>), which looks promising. I’m definitely going to try it, especially since it’s api-compatible with Hugging Face and spaCy. Their proposed development cycle, which first augments the training data, and then tests for bias, robustness, accuracy and fairness seems pretty slick.</p><h2 id=few-shot-learning-is-definitely-worth-a-try>Few-Shot Learning is definitely worth a try<a hidden class=anchor aria-hidden=true href=#few-shot-learning-is-definitely-worth-a-try>#</a></h2><p>Moshe Wasserblat from Intel presented their paper on &ldquo;Efficient Few-Shot Learning Without Prompts,&rdquo; which introduced SetFit. This looks really interesting and I plan to try SetFit on one of my problems where annotated data is difficult to obtain. Especially since one of the authors (Luke Bates) currently resides in Darmstadt. ;-) Link to the Paper: <a href=https://arxiv.org/abs/2209.11055>https://arxiv.org/abs/2209.11055</a></p><h2 id=summary>Summary<a hidden class=anchor aria-hidden=true href=#summary>#</a></h2><p>Overall, the conference lacked substance in some presentations, but it provided great insights into the development of real-world products. I would recommend attending next time.</p></div><footer class=post-footer><ul class=post-tags><li><a href=https://markus.bockhacker.com/tags/nlp/>NLP</a></li><li><a href=https://markus.bockhacker.com/tags/healthcare/>Healthcare</a></li><li><a href=https://markus.bockhacker.com/tags/conference/>Conference</a></li><li><a href=https://markus.bockhacker.com/tags/notes/>Notes</a></li></ul><nav class=paginav><a class=prev href=https://markus.bockhacker.com/posts/2023-04-22_epic-goes-to-germany/><span class=title>« Prev</span><br><span>Epic Goes to Germany: A Snapshot of the Future?</span>
</a><a class=next href=https://markus.bockhacker.com/posts/2021-12-30-death_by_ehr/><span class=title>Next »</span><br><span>Death by EHR</span></a></nav></footer></article></main><footer class=footer><span><a href=/impressum>Impressum / Legal notice</a>
<a href=/datenschutz>Datenschutz / Privacy statement</a>
</span><span>&copy; 2022-2024 M. Bockhacker, licensed under <a href=https://creativecommons.org/licenses/by-sa/4.0/>CC BY-SA 4.0</a>.
</span><span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg>
</a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script></body></html>